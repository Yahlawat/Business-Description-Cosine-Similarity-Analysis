{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f82724",
   "metadata": {},
   "source": [
    "# Business Description Clustering with FinBERT\n",
    "\n",
    "This notebook implements a pipeline for clustering companies based on their business descriptions using FinBERT embeddings and cosine similarity.\n",
    "\n",
    "## Pipeline Steps\n",
    "1. Load and preprocess business descriptions\n",
    "2. Generate embeddings using FinBERT\n",
    "3. Filter relevant business function sentences\n",
    "4. Compute similarity scores\n",
    "5. Save filtered results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5aa30",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import required libraries and ensure dependencies are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d77c41af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahlaw\\AppData\\Local\\Temp\\ipykernel_9952\\82789486.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "c:\\Users\\ahlaw\\OneDrive - UBC\\Documents\\vscode\\Projects\\Business-Description-Clustering\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\ahlaw\\OneDrive - UBC\\Documents\\vscode\\Projects\\Business-Description-Clustering\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "# Constants\n",
    "MODEL_NAME = \"yiyanghkust/finbert-tone\"\n",
    "SIMILARITY_THRESHOLD = 0.75\n",
    "DATA_PATH = \"../data/raw/management_support.csv\"\n",
    "RESULTS_PATH = \"../data/results/filtered_companies.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad9d496",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "Note: FinBERT is case-sensitive as it was trained on financial documents where capitalization carries meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e77183fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 214 companies with 214 total sentences\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Remove special characters and extra whitespace while preserving case.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to clean\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned text with only letters and single spaces\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# Load and process dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.rename(columns={\n",
    "    'Company Name': 'company_name', \n",
    "    'Business Description': 'business_description'\n",
    "}, inplace=True)\n",
    "\n",
    "# Clean descriptions and split into sentences\n",
    "df[\"cleaned_description\"] = df[\"business_description\"].apply(clean_text)\n",
    "df[\"sentences\"] = df[\"cleaned_description\"].apply(sent_tokenize)\n",
    "\n",
    "# Create one row per sentence\n",
    "df_expanded = df.explode(\"sentences\").rename(\n",
    "    columns={\"sentences\": \"individual_sentences\"}\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"Processed\", len(df), \"companies with\", len(df_expanded), \"total sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c923de",
   "metadata": {},
   "source": [
    "## Generate FinBERT Embeddings\n",
    "Create sentence embeddings using the FinBERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b379111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahlaw\\OneDrive - UBC\\Documents\\vscode\\Projects\\Business-Description-Clustering\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ahlaw\\OneDrive - UBC\\Documents\\vscode\\Projects\\Business-Description-Clustering\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "def encode_sentences(sentences: list) -> torch.Tensor:\n",
    "    \"\"\"Generate FinBERT embeddings for a list of sentences.\n",
    "    \n",
    "    Args:\n",
    "        sentences: List of sentences to encode\n",
    "        \n",
    "    Returns:\n",
    "        Tensor of sentence embeddings\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "# Initialize model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Generate embeddings\n",
    "bd_sentences = df_expanded[\"individual_sentences\"].tolist()\n",
    "bd_embeddings = encode_sentences(bd_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6282091",
   "metadata": {},
   "source": [
    "## Filter Business Function Sentences\n",
    "Extract sentences that describe core business functions and activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710424b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 214 to 213 relevant sentences\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "FUNCTION_KEYWORDS = {\n",
    "    \"provides\", \"offers\", \"delivers\", \"specializes\", \"develops\",\n",
    "    \"manufactures\", \"produces\", \"designs\", \"implements\", \"supports\"\n",
    "}\n",
    "\n",
    "def describes_function(sentence: str) -> bool:\n",
    "    \"\"\"Check if sentence contains business function keywords.\n",
    "    \n",
    "    Args:\n",
    "        sentence: Input sentence to check\n",
    "        \n",
    "    Returns:\n",
    "        True if sentence contains function keywords\n",
    "    \"\"\"\n",
    "    return any(word in sentence.lower() for word in FUNCTION_KEYWORDS)\n",
    "\n",
    "def contains_business_activity(sentence: str) -> bool:\n",
    "    \"\"\"Check if sentence contains business-related verbs or nouns.\n",
    "    \n",
    "    Args:\n",
    "        sentence: Input sentence to analyze\n",
    "        \n",
    "    Returns:\n",
    "        True if sentence contains business activity indicators\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    return any(token.pos_ in {\"VERB\", \"NOUN\"} and \n",
    "              token.dep_ in {\"ROOT\", \"pobj\"} for token in doc)\n",
    "\n",
    "# Filter sentences describing business functions\n",
    "df_filtered = df_expanded[df_expanded[\"individual_sentences\"].apply(\n",
    "    lambda x: describes_function(x) or contains_business_activity(x)\n",
    ")]\n",
    "\n",
    "print(f\"Filtered from {len(df_expanded)} to {len(df_filtered)} relevant sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52c2fa",
   "metadata": {},
   "source": [
    "## Compute Similarity Scores\n",
    "Calculate cosine similarity between sentences and apply threshold filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a2d49bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 similar companies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>business_description</th>\n",
       "      <th>similar_sentence</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000 Inc</td>\n",
       "      <td>8000 Inc. provides consultancy services to cor...</td>\n",
       "      <td>Inc provides consultancy services to corporati...</td>\n",
       "      <td>0.7695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Cannabis Company, Inc.</td>\n",
       "      <td>American Cannabis Company, Inc., together with...</td>\n",
       "      <td>American Cannabis Company Inc together with it...</td>\n",
       "      <td>0.7757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CompuMed, Inc.</td>\n",
       "      <td>CompuMed, Inc., an enterprise telemedicine sol...</td>\n",
       "      <td>CompuMed Inc an enterprise telemedicine soluti...</td>\n",
       "      <td>0.7642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CRA International, Inc.</td>\n",
       "      <td>CRA International, Inc., together with its sub...</td>\n",
       "      <td>CRA International Inc together with its subsid...</td>\n",
       "      <td>0.7635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSG Systems International, Inc.</td>\n",
       "      <td>CSG Systems International, Inc., together with...</td>\n",
       "      <td>CSG Systems International Inc together with it...</td>\n",
       "      <td>0.7753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      company_name  \\\n",
       "0                         8000 Inc   \n",
       "1  American Cannabis Company, Inc.   \n",
       "2                   CompuMed, Inc.   \n",
       "3          CRA International, Inc.   \n",
       "4  CSG Systems International, Inc.   \n",
       "\n",
       "                                business_description  \\\n",
       "0  8000 Inc. provides consultancy services to cor...   \n",
       "1  American Cannabis Company, Inc., together with...   \n",
       "2  CompuMed, Inc., an enterprise telemedicine sol...   \n",
       "3  CRA International, Inc., together with its sub...   \n",
       "4  CSG Systems International, Inc., together with...   \n",
       "\n",
       "                                    similar_sentence  similarity_score  \n",
       "0  Inc provides consultancy services to corporati...            0.7695  \n",
       "1  American Cannabis Company Inc together with it...            0.7757  \n",
       "2  CompuMed Inc an enterprise telemedicine soluti...            0.7642  \n",
       "3  CRA International Inc together with its subsid...            0.7635  \n",
       "4  CSG Systems International Inc together with it...            0.7753  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_similar_companies(query: str, threshold: float = SIMILARITY_THRESHOLD) -> pd.DataFrame:\n",
    "    \"\"\"Find companies with similar business descriptions.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query sentence\n",
    "        threshold: Minimum similarity score (default: 0.75)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame of matching companies with similarity scores\n",
    "    \"\"\"\n",
    "    query_embedding = encode_sentences([query])\n",
    "    cosine_scores = F.cosine_similarity(query_embedding, bd_embeddings)\n",
    "    \n",
    "    # Filter results above threshold\n",
    "    filtered_results = [\n",
    "        {\n",
    "            \"company_name\": df_filtered.iloc[idx][\"company_name\"],\n",
    "            \"business_description\": df_filtered.iloc[idx][\"business_description\"],\n",
    "            \"similar_sentence\": df_filtered.iloc[idx][\"individual_sentences\"],\n",
    "            \"similarity_score\": round(score.item(), 4)\n",
    "        }\n",
    "        for score, idx in zip(cosine_scores, range(len(cosine_scores)))\n",
    "        if score.item() >= threshold\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame(filtered_results)\n",
    "\n",
    "# Example search\n",
    "query = \"Provides consultancy services.\"\n",
    "results_df = find_similar_companies(query)\n",
    "print(f\"Found {len(results_df)} similar companies\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc305d",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "078e6821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../data/results/filtered_companies.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure results directory exists\n",
    "os.makedirs(os.path.dirname(RESULTS_PATH), exist_ok=True)\n",
    "\n",
    "# Save filtered results\n",
    "results_df.to_csv(RESULTS_PATH, index=False)\n",
    "print(f\"Results saved to {RESULTS_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
